{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "\n",
    "import preprocessor as p\n",
    "from kneed import  KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from src.preprocessing import normalize,\\\n",
    "                              substitute_label_,\\\n",
    "                              replace_word_index_twitter_\n",
    "\n",
    "\n",
    "# Lexicon polarity\n",
    "data = json.load(open('outputfile.json'))\n",
    "vocabolario_lexicon = json.load(open('data/lexicon_polarity.json'))\n",
    "vocabolario_index_twitter = json.load(open('data/vocabolario_twitter.json'))\n",
    "\n",
    "\n",
    "# Load Sentiment Analysis model\n",
    "with open('src/model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"src/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Da aggiungere quando c'è il database: check, tramite id, se il tweet è già nel db e aggiornare il \n",
    "count dei retweet\"\"\"\n",
    "\n",
    "class Tweet(object):\n",
    "    \"\"\"The class defines a tweet.\n",
    "\n",
    "    Attributes:\n",
    "    tweet_object: twitter streaming API object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 tweet_object,\n",
    "                 vocabolario_lexicon, \n",
    "                 vocabolario_index_twitter):\n",
    "\n",
    "        #self.tweet_object = tweet_object\n",
    "        self.is_a_retweet = self.is_a_retweet(tweet_object)\n",
    "        self.tweet_text = self.get_text(tweet_object)\n",
    "        self.id_tweet = self.get_id_tweet(tweet_object)\n",
    "        self.id_retweet = self.get_id_retweet(tweet_object)\n",
    "        self.num_retweet = self.get_number_retweets(tweet_object)\n",
    "        self.list_hashtags = self.get_hashtag()\n",
    "        self.data_tweet = self.get_date_tweet(tweet_object)\n",
    "        self.data_retweet = self.get_date_retweet(tweet_object)\n",
    "        self.user_tweet_id = self.get_user_tweet(tweet_object)\n",
    "        #self.user_retweet_id = self.get_user_retweet(tweet_object)\n",
    "        self.user_info = self.get_info_user_tweet(tweet_object)\n",
    "        self.normalized_text = self._textNormalization(vocabolario_lexicon,\n",
    "                                                        vocabolario_index_twitter) \n",
    "        self.padding = self._textPadding()\n",
    "        self.sentiment = self.sentiment()\n",
    "        self.changable_attributes = {'num_retweet': self.get_number_retweets(tweet_object),\n",
    "                                     'list_user_retweet': []}\n",
    "        \n",
    "          \n",
    "    def get_text(self, tweet_object):\n",
    "        \"\"\"Get text of tweet without preprocessing.\n",
    "\n",
    "        :return: tweet's text\n",
    "        \"\"\"      \n",
    "        if self.is_a_retweet:\n",
    "            return tweet_object['retweeted_status']['text']\n",
    "\n",
    "        return tweet_object['text']\n",
    "\n",
    "    def get_cleaned_text(self):\n",
    "        \"\"\"Get tweet's content.\n",
    "\n",
    "        :return: tweet's text\n",
    "        \"\"\"\n",
    "        text = self.tweet_text\n",
    "        clean_text = self.text_cleaning(text)\n",
    "        return clean_text\n",
    "        \n",
    "    @staticmethod\n",
    "    def text_cleaning(text_tweet):\n",
    "        \"\"\"Return text without url, emoji and mentions.\n",
    "\n",
    "        :param text_tweet:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION)\n",
    "        clean_text = p.clean(text_tweet)\n",
    "        return clean_text\n",
    "\n",
    "    def get_hashtag(self):\n",
    "        \"\"\"Return the list of hashtags in the tweet.\n",
    "\n",
    "        :return: list of hashtags in the tweet\n",
    "        \"\"\"\n",
    "\n",
    "        tweet_text = self.get_cleaned_text()\n",
    "        p.set_options(p.OPT.HASHTAG)\n",
    "        parsed_tweet = p.parse(tweet_text)\n",
    "        hashtags_ = parsed_tweet.hashtags\n",
    "        if hashtags_ is None:\n",
    "            return []\n",
    "\n",
    "        list_hashtags = [i.match[1:].lower() for i in hashtags_]\n",
    "        return list_hashtags\n",
    "\n",
    "    def is_a_retweet(self, tweet_object):\n",
    "        \"\"\"Tell if the post is a retweet or not.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            assert tweet_object['retweeted_status']\n",
    "            return True\n",
    "        except KeyError:\n",
    "            return False\n",
    "\n",
    "    def get_id_tweet(self, tweet_object):\n",
    "        \"\"\"Return the id of the first tweet\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.is_a_retweet:\n",
    "            return tweet_object['retweeted_status']['id']\n",
    "\n",
    "        return tweet_object['id']\n",
    "\n",
    "    def get_id_retweet(self, tweet_object):\n",
    "        \"\"\"Return the post id.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return tweet_object['id']\n",
    "\n",
    "    def get_number_retweets(self, tweet_object):\n",
    "        \"\"\"Number of retweet.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #if self.is_a_retweet:\n",
    "        #    return tweet_object['retweeted_status']['retweet_count']\n",
    "        \n",
    "        return tweet_object['retweet_count']\n",
    "        \n",
    "    \n",
    "    def get_date_tweet(self, tweet_object):\n",
    "        \"\"\"Publication date of the tweet\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.is_a_retweet:\n",
    "            return tweet_object['retweeted_status']['created_at']\n",
    "        \n",
    "        return tweet_object['created_at']\n",
    "\n",
    "    def get_date_retweet(self, tweet_object):\n",
    "        \"\"\"Pub date of retweet\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        return tweet_object['created_at']\n",
    "    \n",
    "    def get_user_tweet(self, tweet_object):\n",
    "        \"\"\"Return the user id that tweets\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.is_a_retweet:\n",
    "            return tweet_object['retweeted_status']['user']['id']\n",
    "        return tweet_object['user']['id']\n",
    "    \n",
    "    def get_info_user_tweet(self, tweet_object):\n",
    "        \"\"\"Return info of the user that tweets\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        info = {}\n",
    "        if self.is_a_retweet:\n",
    "            user = tweet_object['retweeted_status']['user']\n",
    "            info['name'] = user['name']\n",
    "            info['followers_count'] = user['followers_count']\n",
    "            return info\n",
    "        \n",
    "        user = tweet_object['user']\n",
    "        info['name'] = user['name']\n",
    "        info['followers_count'] = user['followers_count']\n",
    "        return info\n",
    "        \n",
    "    def get_user_retweet(self, tweet_object):\n",
    "        \"\"\"Return the user id that retweets\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        return tweet_object['user']['id']\n",
    "    \n",
    "            \n",
    "    def sentiment(self):\n",
    "        \"\"\"Tell if the tweet is positive or negative\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "  \n",
    "        if self._predictSentiment() == 0:\n",
    "            return 'negative'\n",
    "        \n",
    "        return 'positive'\n",
    "\n",
    "    \n",
    "    def _textPadding(self):\n",
    "        \"\"\"Return the sequence of padded words\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        max_length = 40\n",
    "        pad_text = np.append(np.array(self.normalized_text),\n",
    "                             np.array([0]*(max_length-len(self.normalized_text))))\n",
    "        \n",
    "        return pad_text\n",
    "            \n",
    "    def _textNormalization(self, vocabolario_lexicon, vocabolario_index_twitter):\n",
    "        \"\"\"Return the normalized text for padding.\n",
    "        \n",
    "        Keyword Arguments:\n",
    "        \"\"\"\n",
    "        \n",
    "        token_tweet = p.tokenize(self.tweet_text)\n",
    "        split_normalize_tweet = normalize(token_tweet).split()\n",
    "        replace_and_split_lexicon = (substitute_label_(split_normalize_tweet,\\\n",
    "                                                      vocabolario_lexicon)).split()\n",
    "        to_pad = replace_word_index_twitter_(replace_and_split_lexicon,\\\n",
    "                                            vocabolario_index_twitter)\n",
    "        \n",
    "        return to_pad\n",
    "\n",
    "    def _predictSentiment(self):\n",
    "        \"\"\"Return the sentimenti prediction for the Tweet\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        return loaded_model.predict_classes(np.array([self._textPadding(),]))\n",
    "    \n",
    "    def _updateNumberRetweet(self, tweet_object):\n",
    "        \"\"\"Update attributes\n",
    "        \n",
    "        :return:\"\"\"\n",
    "        \n",
    "        self.changable_attributes['num_retweet'] = max(self.num_retweet,\\\n",
    "                                                       self.get_number_retweets(tweet_object))\n",
    "        \n",
    "    def _updateListUserRetweet(self, tweet_object):\n",
    "        \"\"\"Update lista degli utenti che hanno retwittato\"\"\"\n",
    "        \n",
    "        self.changable_attributes['list_user_retweet'] += [(self.get_user_retweet(tweet_object),\\\n",
    "                                                            self.get_date_retweet(tweet_object))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'changable_attributes': {'list_user_retweet': [], 'num_retweet': 0},\n",
       " 'data_retweet': 'Tue Mar 06 12:05:00 +0000 2018',\n",
       " 'data_tweet': 'Tue Mar 06 12:05:00 +0000 2018',\n",
       " 'id_retweet': 970993648392220672,\n",
       " 'id_tweet': 970993648392220672,\n",
       " 'is_a_retweet': False,\n",
       " 'list_hashtags': ['aria',\n",
       "  '5marzo',\n",
       "  'toscana',\n",
       "  'ambiente',\n",
       "  'inquinamento',\n",
       "  'smog'],\n",
       " 'normalized_text': [12195,\n",
       "  12356,\n",
       "  13219,\n",
       "  4527,\n",
       "  451,\n",
       "  13219,\n",
       "  4341,\n",
       "  13219,\n",
       "  11506,\n",
       "  268,\n",
       "  13219,\n",
       "  13219,\n",
       "  13219],\n",
       " 'num_retweet': 0,\n",
       " 'padding': array([12195, 12356, 13219,  4527,   451, 13219,  4341, 13219, 11506,\n",
       "          268, 13219, 13219, 13219,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0]),\n",
       " 'sentiment': 'negative',\n",
       " 'tweet_text': \"Qualità dell'#aria: i dati rilevati il #5marzo in #Toscana https://t.co/cbJg98X2ID #ambiente #inquinamento #smog\",\n",
       " 'user_info': {'followers_count': 5781, 'name': 'ARPAT'},\n",
       " 'user_tweet_id': 461049017}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet(data[0], vocabolario_lexicon, vocabolario_index_twitter).__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetCollection(object):\n",
    "    \"\"\"The class define the collection of tweets related to\n",
    "    one hashtag.\n",
    "    \n",
    "    Attributes:\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hashtag, collection_totale):\n",
    "        \n",
    "        self.hashtag = hashtag\n",
    "        self.collection = self.collezione(collection_totale)\n",
    "        \n",
    "    def collezione(self, collection_totale):\n",
    "        \"\"\"Return the list of objects in the collection\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        collection = []\n",
    "        for tweet in collection_totale:\n",
    "            for hash_ in tweet.__dict__['list_hashtags']:\n",
    "                if self.hashtag in hash_ and tweet not in collection:\n",
    "                    collection += [tweet]\n",
    "                    \n",
    "        return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hashtag(object):\n",
    "    \"\"\"The class defines a hashtag object.\n",
    "\n",
    "    Attribute:\n",
    "    hashtag_occurrences_collection: occurence\n",
    "                                    of the hashtag in the collection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 hashtag,\n",
    "                 tweet_collection):\n",
    "        \"\"\"Return a hashtag object.\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.hashtag = hashtag\n",
    "        self.lista_tweet = self.get_list_tweet(tweet_collection)\n",
    "        self.lista_user = self.get_list_users()\n",
    "\n",
    "    def get_list_tweet(self, tweet_collection):\n",
    "        \"\"\"Return the list of tweets that contain the hashtag\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        collection = TweetCollection(self.hashtag,\\\n",
    "                                     tweet_collection).__dict__['collection']\n",
    "        lista_tweet = []\n",
    "        \n",
    "        # Considero solo i singoli tweet\n",
    "        for tweet in collection: \n",
    "            attr_tweet = tweet.__dict__\n",
    "            lista_id_tweet = [attr_tweet['id_tweet']]\n",
    "            lista_tweet += lista_id_tweet\n",
    "            \n",
    "        return collection, lista_tweet\n",
    "    \n",
    "    def get_list_users(self):\n",
    "        \"\"\"Return the list of users that tweet or\n",
    "        retweet the hashtag\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        list_users = []\n",
    "        for tweet in self.lista_tweet[0]:\n",
    "            tweet_attr = tweet.__dict__\n",
    "            id_user_tweet = tweet_attr['user_tweet_id']\n",
    "            id_user_retweet = tweet_attr['changable_attributes']['list_user_retweet']\n",
    "            \n",
    "            list_users += [(id_user_tweet, tweet_attr['data_tweet'])] + id_user_retweet\n",
    "            \n",
    "        return list_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtag': 'renzi',\n",
       " 'lista_tweet': ([<__main__.Tweet at 0x11fe98c18>,\n",
       "   <__main__.Tweet at 0x11fe96588>,\n",
       "   <__main__.Tweet at 0x11fe96e10>,\n",
       "   <__main__.Tweet at 0x11fe96e48>,\n",
       "   <__main__.Tweet at 0x11fe96ac8>,\n",
       "   <__main__.Tweet at 0x11fe96860>,\n",
       "   <__main__.Tweet at 0x11fe96eb8>,\n",
       "   <__main__.Tweet at 0x11febc550>,\n",
       "   <__main__.Tweet at 0x11febcb38>,\n",
       "   <__main__.Tweet at 0x11febc3c8>,\n",
       "   <__main__.Tweet at 0x11febc6a0>,\n",
       "   <__main__.Tweet at 0x11febcdd8>,\n",
       "   <__main__.Tweet at 0x11fb189b0>,\n",
       "   <__main__.Tweet at 0x11fb180b8>,\n",
       "   <__main__.Tweet at 0x11fb18eb8>,\n",
       "   <__main__.Tweet at 0x11fb18e80>,\n",
       "   <__main__.Tweet at 0x11fb18d68>,\n",
       "   <__main__.Tweet at 0x11fb18b00>,\n",
       "   <__main__.Tweet at 0x11fb2c080>,\n",
       "   <__main__.Tweet at 0x11fb2cc88>,\n",
       "   <__main__.Tweet at 0x11fb45828>,\n",
       "   <__main__.Tweet at 0x11fb45b00>,\n",
       "   <__main__.Tweet at 0x11fb45c50>,\n",
       "   <__main__.Tweet at 0x11fb452e8>,\n",
       "   <__main__.Tweet at 0x11fb45470>,\n",
       "   <__main__.Tweet at 0x11fc1f3c8>,\n",
       "   <__main__.Tweet at 0x11fc1f438>,\n",
       "   <__main__.Tweet at 0x11fc1fac8>,\n",
       "   <__main__.Tweet at 0x11fc1f9e8>,\n",
       "   <__main__.Tweet at 0x11fc1f320>,\n",
       "   <__main__.Tweet at 0x11fc1ffd0>,\n",
       "   <__main__.Tweet at 0x11fc1fd30>,\n",
       "   <__main__.Tweet at 0x11fc1f940>,\n",
       "   <__main__.Tweet at 0x11fc3aef0>,\n",
       "   <__main__.Tweet at 0x11fc3ae80>,\n",
       "   <__main__.Tweet at 0x11fc3ac50>,\n",
       "   <__main__.Tweet at 0x11fc575c0>,\n",
       "   <__main__.Tweet at 0x11f7cb940>,\n",
       "   <__main__.Tweet at 0x11f7cb6a0>,\n",
       "   <__main__.Tweet at 0x11f7c7160>,\n",
       "   <__main__.Tweet at 0x11f7c1c88>,\n",
       "   <__main__.Tweet at 0x11f7c63c8>,\n",
       "   <__main__.Tweet at 0x11f7c1ef0>,\n",
       "   <__main__.Tweet at 0x11f7cd390>,\n",
       "   <__main__.Tweet at 0x11f7bfdd8>,\n",
       "   <__main__.Tweet at 0x11f7bf358>,\n",
       "   <__main__.Tweet at 0x11f7bf748>,\n",
       "   <__main__.Tweet at 0x11f7bd4a8>,\n",
       "   <__main__.Tweet at 0x11f7bd240>,\n",
       "   <__main__.Tweet at 0x11f7bd198>,\n",
       "   <__main__.Tweet at 0x11f7bd128>,\n",
       "   <__main__.Tweet at 0x11f7bd438>,\n",
       "   <__main__.Tweet at 0x11f7bd2e8>,\n",
       "   <__main__.Tweet at 0x11f7bd908>,\n",
       "   <__main__.Tweet at 0x11f7c5780>,\n",
       "   <__main__.Tweet at 0x11f739390>,\n",
       "   <__main__.Tweet at 0x11f7c4eb8>,\n",
       "   <__main__.Tweet at 0x11f7c4e10>,\n",
       "   <__main__.Tweet at 0x11f718e48>,\n",
       "   <__main__.Tweet at 0x11fb61978>,\n",
       "   <__main__.Tweet at 0x11fb74a90>,\n",
       "   <__main__.Tweet at 0x11fb80f28>,\n",
       "   <__main__.Tweet at 0x11fb802b0>,\n",
       "   <__main__.Tweet at 0x11fbb66d8>,\n",
       "   <__main__.Tweet at 0x11fccb748>,\n",
       "   <__main__.Tweet at 0x11fccb470>,\n",
       "   <__main__.Tweet at 0x11fccbf98>,\n",
       "   <__main__.Tweet at 0x11fccbf28>,\n",
       "   <__main__.Tweet at 0x11fae2390>,\n",
       "   <__main__.Tweet at 0x11f9ea080>],\n",
       "  [970540855307198466,\n",
       "   970729807272136705,\n",
       "   970956245535510528,\n",
       "   970982492126826497,\n",
       "   970966104221863936,\n",
       "   970931504196046850,\n",
       "   970929800469729280,\n",
       "   970993245751791617,\n",
       "   970992908689137666,\n",
       "   970979326534529025,\n",
       "   970992747166527489,\n",
       "   970604889092120577,\n",
       "   970603691643457536,\n",
       "   970988947387158528,\n",
       "   970727194610798594,\n",
       "   970991312546811904,\n",
       "   970991222243414017,\n",
       "   970991123517853697,\n",
       "   970990461094645760,\n",
       "   970990130080165888,\n",
       "   970985557810667520,\n",
       "   970988846430203905,\n",
       "   970988696609677313,\n",
       "   970715725865381888,\n",
       "   970988435908460544,\n",
       "   970968140455825408,\n",
       "   970988056521203712,\n",
       "   970987933317681153,\n",
       "   970987172261187585,\n",
       "   970987533185282048,\n",
       "   970987579502940160,\n",
       "   970987142494277632,\n",
       "   970987068141817856,\n",
       "   970281534208036864,\n",
       "   970985616266711042,\n",
       "   970985593516756992,\n",
       "   970985205006766080,\n",
       "   970983220559994880,\n",
       "   970983168739348480,\n",
       "   970981904609660928,\n",
       "   970923810672271361,\n",
       "   970718834746445825,\n",
       "   970781133205114881,\n",
       "   970712846450520064,\n",
       "   970713923203883010,\n",
       "   970783703982051328,\n",
       "   970620646827937793,\n",
       "   970978779198783488,\n",
       "   970825874915328000,\n",
       "   970978336720736257,\n",
       "   970978277010657280,\n",
       "   970978215715012608,\n",
       "   970978142050545664,\n",
       "   970977985858801664,\n",
       "   970977854036078593,\n",
       "   970947776417796097,\n",
       "   970976775693127680,\n",
       "   970976303984898048,\n",
       "   970976177753149441,\n",
       "   971019333727129601,\n",
       "   970738961781088256,\n",
       "   971003213112664064,\n",
       "   971001576155504645,\n",
       "   970630964379516935,\n",
       "   968061181301805056,\n",
       "   968049151949852672,\n",
       "   967535124094078978,\n",
       "   967526325887098880,\n",
       "   967393966768508928,\n",
       "   970714766225354753]),\n",
       " 'lista_user': [(3398885945, 'Mon Mar 05 06:05:46 +0000 2018'),\n",
       "  (1566553698, 'Mon Mar 05 18:36:35 +0000 2018'),\n",
       "  (3096871079, 'Tue Mar 06 09:36:23 +0000 2018'),\n",
       "  (501691674, 'Tue Mar 06 11:58:22 +0000 2018'),\n",
       "  (551018622, 'Tue Mar 06 11:54:00 +0000 2018'),\n",
       "  (541695689, 'Tue Mar 06 11:48:42 +0000 2018'),\n",
       "  (3404776456, 'Tue Mar 06 11:47:21 +0000 2018'),\n",
       "  (4589805027, 'Tue Mar 06 11:45:34 +0000 2018'),\n",
       "  (266066911, 'Tue Mar 06 11:37:31 +0000 2018'),\n",
       "  (1425435948, 'Tue Mar 06 11:36:31 +0000 2018'),\n",
       "  (433604815, 'Tue Mar 06 11:33:47 +0000 2018'),\n",
       "  (335341927, 'Tue Mar 06 11:30:46 +0000 2018'),\n",
       "  (500835651, 'Tue Mar 06 11:30:11 +0000 2018'),\n",
       "  (447439107, 'Tue Mar 06 11:29:14 +0000 2018'),\n",
       "  (4876948905, 'Tue Mar 06 11:27:58 +0000 2018'),\n",
       "  (2465000210, 'Tue Mar 06 11:26:33 +0000 2018'),\n",
       "  (837660650520342529, 'Tue Mar 06 11:26:20 +0000 2018'),\n",
       "  (564068843, 'Tue Mar 06 11:24:14 +0000 2018'),\n",
       "  (55049219, 'Tue Mar 06 11:24:12 +0000 2018'),\n",
       "  (495323941, 'Tue Mar 06 11:23:30 +0000 2018'),\n",
       "  (3047137438, 'Tue Mar 06 11:22:36 +0000 2018'),\n",
       "  (837270233140326400, 'Tue Mar 06 11:21:48 +0000 2018'),\n",
       "  (734385926240112641, 'Tue Mar 06 11:20:07 +0000 2018'),\n",
       "  (2945849914, 'Tue Mar 06 11:19:02 +0000 2018'),\n",
       "  (703508760807997440, 'Tue Mar 06 11:18:23 +0000 2018'),\n",
       "  (770237165284491265, 'Tue Mar 06 11:18:07 +0000 2018'),\n",
       "  (476928206, 'Tue Mar 06 11:15:46 +0000 2018'),\n",
       "  (955794512005292034, 'Tue Mar 06 11:14:41 +0000 2018'),\n",
       "  (230251192, 'Tue Mar 06 11:12:33 +0000 2018'),\n",
       "  (156359333, 'Tue Mar 06 11:10:16 +0000 2018'),\n",
       "  (598077233, 'Tue Mar 06 11:10:10 +0000 2018'),\n",
       "  (4178168602, 'Tue Mar 06 11:09:56 +0000 2018'),\n",
       "  (79411170, 'Tue Mar 06 11:07:56 +0000 2018'),\n",
       "  (1177051177, 'Tue Mar 06 11:07:29 +0000 2018'),\n",
       "  (96389952, 'Tue Mar 06 11:05:10 +0000 2018'),\n",
       "  (32871274, 'Tue Mar 06 11:04:33 +0000 2018'),\n",
       "  (931536680758251520, 'Tue Mar 06 11:03:53 +0000 2018'),\n",
       "  (840934380839305217, 'Tue Mar 06 11:01:29 +0000 2018'),\n",
       "  (935148661356531712, 'Tue Mar 06 11:00:29 +0000 2018'),\n",
       "  (1015512337, 'Tue Mar 06 11:00:21 +0000 2018'),\n",
       "  (197555550, 'Tue Mar 06 11:00:06 +0000 2018'),\n",
       "  (960510194064285696, 'Tue Mar 06 10:56:55 +0000 2018'),\n",
       "  (909156725659402240, 'Tue Mar 06 10:56:53 +0000 2018'),\n",
       "  (719093893795614720, 'Tue Mar 06 10:55:07 +0000 2018'),\n",
       "  (873992653704220676, 'Tue Mar 06 11:20:40 +0000 2018'),\n",
       "  (367636617, 'Tue Mar 06 11:48:41 +0000 2018'),\n",
       "  (873992653704220676, 'Tue Mar 06 11:20:40 +0000 2018'),\n",
       "  (52424550, 'Tue Mar 06 10:15:33 +0000 2018'),\n",
       "  (3308422191, 'Tue Mar 06 12:05:17 +0000 2018'),\n",
       "  (450882742, 'Tue Mar 06 11:49:06 +0000 2018'),\n",
       "  (970754186035040257, 'Tue Mar 06 11:46:48 +0000 2018'),\n",
       "  (496230584, 'Tue Mar 06 11:45:27 +0000 2018'),\n",
       "  (885873404078903297, 'Tue Mar 06 11:43:43 +0000 2018'),\n",
       "  (703360096944988160, 'Tue Mar 06 11:27:32 +0000 2018'),\n",
       "  (183283202, 'Tue Mar 06 11:17:47 +0000 2018'),\n",
       "  (329492939, 'Tue Mar 06 07:58:04 +0000 2018'),\n",
       "  (858322712, 'Tue Mar 06 11:59:28 +0000 2018'),\n",
       "  (278227018, 'Tue Mar 06 11:47:13 +0000 2018'),\n",
       "  (588276310, 'Tue Mar 06 11:41:28 +0000 2018'),\n",
       "  (845530674, 'Tue Mar 06 11:37:07 +0000 2018'),\n",
       "  (438798142, 'Tue Mar 06 11:25:30 +0000 2018'),\n",
       "  (18447103, 'Tue Mar 06 11:24:26 +0000 2018'),\n",
       "  (2870212265, 'Tue Mar 06 11:12:47 +0000 2018'),\n",
       "  (892954382, 'Tue Mar 06 07:51:18 +0000 2018'),\n",
       "  (396756630, 'Tue Mar 06 12:03:41 +0000 2018'),\n",
       "  (2424256072, 'Tue Mar 06 11:55:21 +0000 2018'),\n",
       "  (305255857, 'Tue Mar 06 11:52:54 +0000 2018'),\n",
       "  (847200666, 'Tue Mar 06 11:51:34 +0000 2018'),\n",
       "  (3382770388, 'Tue Mar 06 11:47:49 +0000 2018'),\n",
       "  (399609372, 'Tue Mar 06 11:29:45 +0000 2018'),\n",
       "  (416340182, 'Tue Mar 06 11:15:13 +0000 2018'),\n",
       "  (608138818, 'Tue Mar 06 11:09:34 +0000 2018'),\n",
       "  (64139825, 'Tue Mar 06 11:07:57 +0000 2018'),\n",
       "  (545384133, 'Tue Mar 06 11:02:12 +0000 2018'),\n",
       "  (2247033698, 'Tue Mar 06 12:03:24 +0000 2018'),\n",
       "  (271593542, 'Tue Mar 06 12:02:04 +0000 2018'),\n",
       "  (35951856, 'Tue Mar 06 11:08:06 +0000 2018'),\n",
       "  (128587748, 'Tue Mar 06 11:35:27 +0000 2018'),\n",
       "  (35951856, 'Tue Mar 06 11:08:06 +0000 2018'),\n",
       "  (829445018796515328, 'Tue Mar 06 12:01:25 +0000 2018'),\n",
       "  (791671886690353153, 'Mon Mar 05 10:20:13 +0000 2018'),\n",
       "  (555278672, 'Tue Mar 06 11:44:19 +0000 2018'),\n",
       "  (298123237, 'Mon Mar 05 10:15:27 +0000 2018'),\n",
       "  (461072651, 'Tue Mar 06 11:46:19 +0000 2018'),\n",
       "  (3175578989, 'Tue Mar 06 11:49:45 +0000 2018'),\n",
       "  (461072651, 'Tue Mar 06 11:46:19 +0000 2018'),\n",
       "  (3331874607, 'Mon Mar 05 18:26:13 +0000 2018'),\n",
       "  (2794375445, 'Tue Mar 06 11:40:01 +0000 2018'),\n",
       "  (270838136, 'Tue Mar 06 11:55:43 +0000 2018'),\n",
       "  (402636633, 'Tue Mar 06 11:55:22 +0000 2018'),\n",
       "  (2787225059, 'Tue Mar 06 11:54:58 +0000 2018'),\n",
       "  (3331440249, 'Tue Mar 06 11:52:20 +0000 2018'),\n",
       "  (2418808928, 'Tue Mar 06 11:51:01 +0000 2018'),\n",
       "  (2399172568, 'Tue Mar 06 11:32:51 +0000 2018'),\n",
       "  (2399172568, 'Tue Mar 06 11:32:51 +0000 2018'),\n",
       "  (715587855150616578, 'Tue Mar 06 11:45:55 +0000 2018'),\n",
       "  (1013093844, 'Tue Mar 06 11:45:20 +0000 2018'),\n",
       "  (1566553698, 'Mon Mar 05 17:40:38 +0000 2018'),\n",
       "  (807911164965490689, 'Tue Mar 06 11:43:01 +0000 2018'),\n",
       "  (2409382352, 'Tue Mar 06 11:35:40 +0000 2018'),\n",
       "  (723584112586530817, 'Tue Mar 06 11:32:58 +0000 2018'),\n",
       "  (970733319116730368, 'Tue Mar 06 11:27:37 +0000 2018'),\n",
       "  (4188604709, 'Tue Mar 06 11:22:28 +0000 2018'),\n",
       "  (4859642074, 'Tue Mar 06 11:21:51 +0000 2018'),\n",
       "  (788857343471710208, 'Tue Mar 06 11:08:09 +0000 2018'),\n",
       "  (2336648684, 'Tue Mar 06 11:44:17 +0000 2018'),\n",
       "  (75259906, 'Tue Mar 06 10:23:39 +0000 2018'),\n",
       "  (531520956, 'Tue Mar 06 11:42:47 +0000 2018'),\n",
       "  (214617755, 'Tue Mar 06 11:42:18 +0000 2018'),\n",
       "  (4850508431, 'Tue Mar 06 11:39:16 +0000 2018'),\n",
       "  (4850508431, 'Tue Mar 06 11:39:16 +0000 2018'),\n",
       "  (634744796, 'Tue Mar 06 11:40:42 +0000 2018'),\n",
       "  (634744796, 'Tue Mar 06 11:40:42 +0000 2018'),\n",
       "  (33230351, 'Tue Mar 06 11:40:53 +0000 2018'),\n",
       "  (2654757931, 'Tue Mar 06 11:39:09 +0000 2018'),\n",
       "  (145439895, 'Tue Mar 06 11:38:51 +0000 2018'),\n",
       "  (2801540412, 'Sun Mar 04 12:55:19 +0000 2018'),\n",
       "  (560127853, 'Tue Mar 06 11:33:05 +0000 2018'),\n",
       "  (627579169, 'Tue Mar 06 11:33:00 +0000 2018'),\n",
       "  (737338965481623552, 'Tue Mar 06 11:31:27 +0000 2018'),\n",
       "  (4382870122, 'Tue Mar 06 11:23:34 +0000 2018'),\n",
       "  (2475394267, 'Tue Mar 06 11:23:22 +0000 2018'),\n",
       "  (230775930, 'Tue Mar 06 11:18:20 +0000 2018'),\n",
       "  (85066223, 'Tue Mar 06 07:27:30 +0000 2018'),\n",
       "  (107729277, 'Tue Mar 06 11:06:37 +0000 2018'),\n",
       "  (1566553698, 'Mon Mar 05 17:52:59 +0000 2018'),\n",
       "  (2977944652, 'Mon Mar 05 22:00:33 +0000 2018'),\n",
       "  (3331874607, 'Mon Mar 05 17:29:12 +0000 2018'),\n",
       "  (3331874607, 'Mon Mar 05 17:33:28 +0000 2018'),\n",
       "  (965239081, 'Mon Mar 05 22:10:45 +0000 2018'),\n",
       "  (4863618933, 'Tue Mar 06 11:02:07 +0000 2018'),\n",
       "  (1372461787, 'Tue Mar 06 11:00:50 +0000 2018'),\n",
       "  (139188966, 'Tue Mar 06 11:00:16 +0000 2018'),\n",
       "  (831981618, 'Tue Mar 06 10:57:23 +0000 2018'),\n",
       "  (797506411148312576, 'Tue Mar 06 10:56:45 +0000 2018'),\n",
       "  (1314231894, 'Tue Mar 06 10:55:43 +0000 2018'),\n",
       "  (225490204, 'Tue Mar 06 10:54:54 +0000 2018'),\n",
       "  (17565436, 'Mon Mar 05 11:22:50 +0000 2018'),\n",
       "  (462338524, 'Tue Mar 06 11:05:55 +0000 2018'),\n",
       "  (965239081, 'Tue Mar 06 00:58:20 +0000 2018'),\n",
       "  (109252389, 'Tue Mar 06 11:04:10 +0000 2018'),\n",
       "  (951741971290378240, 'Tue Mar 06 11:03:55 +0000 2018'),\n",
       "  (1119918066, 'Tue Mar 06 11:03:41 +0000 2018'),\n",
       "  (3309811967, 'Tue Mar 06 11:03:23 +0000 2018'),\n",
       "  (783277412482215936, 'Tue Mar 06 11:02:46 +0000 2018'),\n",
       "  (970652452788822017, 'Tue Mar 06 11:02:14 +0000 2018'),\n",
       "  (202220813, 'Tue Mar 06 09:02:43 +0000 2018'),\n",
       "  (109252389, 'Tue Mar 06 10:57:57 +0000 2018'),\n",
       "  (280999799, 'Tue Mar 06 10:56:05 +0000 2018'),\n",
       "  (3331874607, 'Tue Mar 06 10:55:35 +0000 2018'),\n",
       "  (161464462, 'Tue Mar 06 13:47:04 +0000 2018'),\n",
       "  (2238011889, 'Mon Mar 05 19:12:58 +0000 2018'),\n",
       "  (400383332, 'Tue Mar 06 12:43:01 +0000 2018'),\n",
       "  (1121635200, 'Tue Mar 06 12:36:30 +0000 2018'),\n",
       "  (815549036, 'Mon Mar 05 12:03:50 +0000 2018'),\n",
       "  (2518577318, 'Mon Feb 26 09:52:25 +0000 2018'),\n",
       "  (2518577318, 'Mon Feb 26 09:04:37 +0000 2018'),\n",
       "  (231726084, 'Sat Feb 24 23:02:04 +0000 2018'),\n",
       "  (717039627916484608, 'Sat Feb 24 22:27:06 +0000 2018'),\n",
       "  (79991599, 'Sat Feb 24 13:41:09 +0000 2018'),\n",
       "  (962273174225375232, 'Fri Mar 02 21:39:56 +0000 2018'),\n",
       "  (836271002, 'Fri Mar 02 21:38:28 +0000 2018'),\n",
       "  (2204128029, 'Fri Mar 02 21:30:53 +0000 2018'),\n",
       "  (532222780, 'Fri Mar 02 21:27:21 +0000 2018'),\n",
       "  (346014901, 'Fri Mar 02 21:26:50 +0000 2018'),\n",
       "  (469548537, 'Mon Mar 05 17:36:49 +0000 2018')]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hashtag('renzi', collection_totale).__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphHashtag(object):\n",
    "    \"\"\"This class define the graph of hashtags.\n",
    "    \n",
    "    Attributes:\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, edge_weights, tweet_collection, with_jaccard):\n",
    "        self.with_jaccard = with_jaccard\n",
    "        self.G = self.create_graph(edge_weights, tweet_collection)\n",
    "        self.clusters = self.topic_content()\n",
    "        self.tweet_clusters = self.tweet_cluster(tweet_collection)\n",
    "        \n",
    "    \n",
    "    def create_graph(self, edge_weights, tweet_collection):\n",
    "        \"\"\"Return the graph of hashtags.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        G.add_weighted_edges_from(self._defineEdges(edge_weights, tweet_collection, self.with_jaccard))\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def topic_content(self):\n",
    "        \"\"\"Return the list of hashtag in the topic\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        partitions = self._graphPartitioning()\n",
    "        \n",
    "        hashtag_cluster = list(zip(self.G.nodes(),partitions.labels_))\n",
    "\n",
    "        cluster_list_hashtag = defaultdict(list)\n",
    "        for hash_, class_ in hashtag_cluster:\n",
    "            cluster_list_hashtag[class_] += [hash_]\n",
    "            \n",
    "        return cluster_list_hashtag\n",
    "    \n",
    "    def tweet_cluster(self, tweet_collection):\n",
    "        \"\"\"Return the list of tweets per topic\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        cluster_name = self._renameClusters(tweet_collection)\n",
    "        hash_cluster = {hash_:cluster \\\n",
    "                for cluster,list_hash in self.clusters.items()\\\n",
    "                for hash_ in list_hash}\n",
    "        \n",
    "        tweet_cluster = {}\n",
    "\n",
    "        for tweet in tweet_collection:\n",
    "            tweet_attr = tweet.__dict__\n",
    "            tweet_id = tweet_attr['id_tweet']\n",
    "            list_clusters = [hash_cluster[h] for h in tweet_attr['list_hashtags'] if h in self.G.nodes()]\n",
    "            tweet_cluster[tweet] = list(set(list_clusters))\n",
    "        \n",
    "        \"\"\"Sono esclusi i tweet che non appartengono a nessun cluster\"\"\"\n",
    "        cluster_tweet = defaultdict(list)\n",
    "        for tweet, list_cluster in tweet_cluster.items():\n",
    "            if len(list_cluster) > 0:\n",
    "                for cluster in list_cluster:\n",
    "                    cluster_tweet[cluster_name[cluster]] += [tweet]\n",
    "                    \n",
    "        return cluster_tweet\n",
    "        \n",
    "    \n",
    "    def _adjacencyMatrixReduction(self):\n",
    "        \"\"\"Return the matrix projected in the lower dimensional \n",
    "        principal components subspace.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        #import numpy as np\n",
    "        #import networkx as nx\n",
    "        #from scipy import sparse\n",
    "\n",
    "        \n",
    "        #degree_dict = nx.degree(self.G)\n",
    "        #degree_list = [x[1] for x in degree_dict]\n",
    "        #lap_matrix = sparse.diags(degree_list, 0)-nx.adjacency_matrix(self.G)\n",
    "        #eigval, eigvec = sparse.linalg.eigsh(lap_matrix, 2, sigma=0, which='LM')\n",
    "        \n",
    "        adjacency_matrix = nx.to_numpy_matrix(self.G)\n",
    "        X = adjacency_matrix\n",
    "        pca = PCA()\n",
    "        pca.fit(X)\n",
    "        variance = pca.explained_variance_ratio_\n",
    "        num_components = np.argmax(np.cumsum(variance)>.9)\n",
    "        print (num_components)\n",
    "\n",
    "        X = adjacency_matrix\n",
    "        pca = PCA(n_components=num_components,svd_solver = 'arpack' )\n",
    "        pca.fit(X) \n",
    "        dimensionality_reduction = pca.fit_transform(X)\n",
    "        \n",
    "        return dimensionality_reduction\n",
    "    \n",
    "    def _graphPartitioning(self, max_k=50):\n",
    "        \"\"\"Give back the partitions.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        X = self._adjacencyMatrixReduction()\n",
    "        distortions = []\n",
    "        K = range(1,max_k)\n",
    "        for k in K:\n",
    "            kmeanModel = KMeans(n_clusters=k).fit(X)\n",
    "            distortions += [sum(np.min(cdist(X, \n",
    "                                             kmeanModel.cluster_centers_, \n",
    "                                             'euclidean'), \n",
    "                                       axis=1))\\\n",
    "                            / X.shape[0]]\n",
    "\n",
    "        number_partitions = KneeLocator(list(K), \n",
    "                                        distortions, \n",
    "                                        invert=False, \n",
    "                                        direction='decreasing')\n",
    "        \n",
    "        return KMeans(n_clusters=number_partitions.knee).fit(X)\n",
    "    \n",
    "    def _defineEdges(self, edge_weights, tweet_collection, jaccard=True):\n",
    "        \"\"\"Return the list of weighted edges.\n",
    "        \n",
    "        :return:\n",
    "        \n",
    "        Keyword Arguments\n",
    "        :param:\n",
    "        \"\"\"\n",
    "        \n",
    "        edge_weights = {key:w for key, w in edge_weights.items() if w > 4}\n",
    "        \n",
    "        \n",
    "        list_obj_hashtag = {}\n",
    "        list_weighted_edges = []\n",
    "        for h_1, h_2 in edge_weights.keys(): # Questa parte va integrata \n",
    "                                             # nel processo di ingestion \n",
    "                                             # del singolo tweet al fine\n",
    "                                             # di snellire la computazione\n",
    "            if h_1 not in list_obj_hashtag:\n",
    "                hashtag_1 = len(Hashtag(h_1, tweet_collection)\\\n",
    "                                .__dict__['lista_tweet'][1])\n",
    "                list_obj_hashtag[h_1] = hashtag_1\n",
    "            else:\n",
    "                hashtag_1 = list_obj_hashtag[h_1]\n",
    "\n",
    "            if h_2 not in list_obj_hashtag:\n",
    "                hashtag_2 = len(Hashtag(h_2, tweet_collection)\\\n",
    "                                .__dict__['lista_tweet'][1])\n",
    "                list_obj_hashtag[h_2] = hashtag_2\n",
    "            else:\n",
    "                hashtag_2 = list_obj_hashtag[h_2]\n",
    "                    \n",
    "            if jaccard:\n",
    "                list_weighted_edges += [(h_1, \n",
    "                                     h_2, \n",
    "                                     edge_weights[(h_1, h_2)]\\\n",
    "                                     /(hashtag_1 + hashtag_2))]\n",
    "            else:\n",
    "               \n",
    "                \n",
    "                list_weighted_edges += [(h_1, \n",
    "                                         h_2, \n",
    "                                         edge_weights[(h_1, h_2)])]\n",
    "        \n",
    "        return list_weighted_edges       \n",
    "    \n",
    "    def _defineNodes(self, edge_weights, tweet_collection):\n",
    "        \"\"\"Get the list of nodes\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        list_nodes = []\n",
    "        edges = self._defineEdges(edge_weights, tweet_collection, jaccard=self.with_jaccard)\n",
    "        for h_1, h_2, w in edges:\n",
    "            list_nodes += [h_1, h_2]\n",
    "            \n",
    "        return set(list_nodes)\n",
    "    \n",
    "    def _renameClusters(self, tweet_collection):\n",
    "        \"\"\"Map the cluster to a name corresponding to the \n",
    "        most occurrent word.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        name_cluster = {}\n",
    "        for cluster, list_hash in self.clusters.items():\n",
    "            list_occ = []\n",
    "            for h in list_hash:\n",
    "                list_occ += [len(Hashtag(h, tweet_collection).__dict__['lista_tweet'])]\n",
    "\n",
    "            name_cluster[cluster] = list_hash[np.argmax(list_occ)]\n",
    "            \n",
    "        return name_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Topic(object):\n",
    "    \"\"\"The class defines the info of a topic.\n",
    "    \n",
    "    Attributes:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tweet_clusters, topic):\n",
    "        self.topic = topic\n",
    "        self.tweet_topic = self.tweet_topic(tweet_clusters)\n",
    "        \n",
    "    def tweet_topic(self, tweet_clusters):\n",
    "        \"\"\"Get tweets in the topic.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        return tweet_clusters[self.topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_retweet(lista_tweet):\n",
    "        \"\"\"Return the list of top retweets\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        list_num_retweet = []\n",
    "        for tweet in lista_tweet:\n",
    "            tweet_attr = tweet.__dict__\n",
    "            num_retweet = tweet_attr['num_retweet']\n",
    "            text_tweet = tweet.text_cleaning(tweet_attr['tweet_text'])\n",
    "            user_info = tweet_attr['user_info']\n",
    "            list_num_retweet += [(num_retweet,\\\n",
    "                                  text_tweet,\\\n",
    "                                  user_info)]\n",
    "            \n",
    "        sort_retweet = sorted(list_num_retweet,key=itemgetter(0), reverse=True)[:10]\n",
    "        \n",
    "        top_10_retweet = []\n",
    "        for i, t in enumerate(sort_retweet):\n",
    "            x = i+1\n",
    "            y = t[0]\n",
    "            label = t[1] + '\\n' + 'Autore: ' + t[2]['name'] + '\\n' \\\n",
    "                    + 'Followers: ' + str(t[2]['followers_count'])\n",
    "                                           \n",
    "            top_10_retweet += [{'x':x, 'y':y, 'label':label}]\n",
    "            \n",
    "        return top_10_retweet\n",
    "    \n",
    "\n",
    "def sentiment_percentage(lista_tweet):\n",
    "        \"\"\"Return the percentage of positive and \n",
    "        negative tweets.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        sentiment_tweet = []\n",
    "        for tweet in lista_tweet:\n",
    "            tweet_attr = tweet.__dict__\n",
    "            sentiment_tweet += [tweet_attr['sentiment']]\n",
    "            \n",
    "        count_sentiment = collections.Counter(sentiment_tweet)\n",
    "        total = len(sentiment_tweet)\n",
    "        percentuali_sentiment = [{'x':1, 'y':round(count_sentiment['positive']/total*100,1)},\n",
    "                                 {'x':2, 'y':round(count_sentiment['negative']/total*100,1)}]\n",
    "            \n",
    "        return percentuali_sentiment\n",
    "\n",
    "def manipulate_date(lista_date):\n",
    "    \"\"\"Return the manipulate dates.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    ts = pd.to_datetime(lista_date)\n",
    "    ts_list = []\n",
    "    for time in ts:\n",
    "        t = str(time)\n",
    "        t_day = t[:10]\n",
    "        t_hour = t[10:13] + ':00:00'\n",
    "        t_rest = t[19:]\n",
    "\n",
    "        ts_list += [t_day + t_hour + t_rest]\n",
    "\n",
    "    return ts_list\n",
    "\n",
    "def unique_cumulative_users(lista_tweet):\n",
    "    \"\"\"Return the cumulative sum of unique users.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    list_date_id = []\n",
    "    for tweet in lista_tweet:\n",
    "        tweet_attr = tweet.__dict__\n",
    "        list_date_id += tweet_attr['changable_attributes']['list_user_retweet']\n",
    "\n",
    "\n",
    "    lista_date = [j for i, j in list_date_id]\n",
    "    ts_list = manipulate_date(lista_date)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['Time'] = ts_list\n",
    "    df['user'] = [i for i, j in list_date_id]\n",
    "    df['counter'] = [1] * len(list_date_id)\n",
    "\n",
    "    df.sort_values(by='Time', inplace=True)\n",
    "    unique_count = df.drop_duplicates('user', keep='first')\\\n",
    "                     .groupby('Time')['counter']\\\n",
    "                     .sum()\n",
    "    cumulative_unique_user = unique_count.cumsum()\n",
    "\n",
    "    list_unici_utenti = []\n",
    "    for i in cumulative_unique_user.index:\n",
    "        list_unici_utenti += [{'x': str(i),\n",
    "                               'y': int(cumulative_unique_user.loc[i])}]\n",
    "\n",
    "    return list_unici_utenti\n",
    "\n",
    "def stream_tweet(lista_tweet, sentimento='negative'):\n",
    "    \"\"\"Return the stram of positive/negative tweets\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    list_date = []\n",
    "    for tweet in lista_tweet:\n",
    "        tweet_attr = tweet.__dict__\n",
    "        if tweet_attr['sentiment'] == sentimento:\n",
    "            list_date += [tweet_attr['data_retweet']]\n",
    "\n",
    "    ts_list = manipulate_date(list_date)\n",
    "\n",
    "    ts = pd.to_datetime(ts_list)\n",
    "    df = pd.DataFrame()\n",
    "    df['Time'] = ts\n",
    "    df['freq'] = [1] * len(ts)\n",
    "\n",
    "    grouped = df.groupby('Time').sum()\n",
    "    list_hours = []\n",
    "    for i in grouped.index:\n",
    "        list_hours += [{'a': str(i), 'b': int(grouped.loc[i][0])}]\n",
    "\n",
    "    return list_hours\n",
    "\n",
    "def get_list_hashtags(lista_tweet):\n",
    "    \"\"\"Return the list of co-occurrent hashtags.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    list_hashtags = []\n",
    "    for tweet in lista_tweet:\n",
    "        tweet_attr = tweet.__dict__\n",
    "        list_hashtags += tweet_attr['list_hashtags']\n",
    "\n",
    "    return collections.Counter(list_hashtags).most_common(11)[1:]\n",
    "\n",
    "def co_occurrences(lista_hashtag):\n",
    "    \"\"\"Return the top 10 co-occurrent hashtags\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    lista_co_occ = []\n",
    "    for i, hash_ in enumerate(lista_hashtag):\n",
    "        lista_co_occ += [{'x': i + 1, 'y': hash_[1], 'label': '#' + hash_[0]}]\n",
    "\n",
    "    return lista_co_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Simulazione dell'arrivo dei tweet\"\"\"\n",
    "list_id_tweet = []\n",
    "list_hashtags = []\n",
    "collection_totale = []\n",
    "edges_weight = defaultdict(int)\n",
    "\n",
    "for tweet in data:\n",
    "    \n",
    "    object_tweet = Tweet(tweet, vocabolario_lexicon, vocabolario_index_twitter)\n",
    "    tweet_attr = object_tweet.__dict__\n",
    "    id_tweet = tweet_attr['id_tweet']\n",
    "    list_hashtag = tweet_attr['list_hashtags']\n",
    "    \n",
    "    if id_tweet not in list_id_tweet:\n",
    "        list_id_tweet += [id_tweet]\n",
    "        collection_totale += [object_tweet]\n",
    "        list_hashtags += list_hashtag\n",
    "        choose_two_hashtag = list(itertools.combinations(list_hashtag, 2))\n",
    "        for edge in choose_two_hashtag:\n",
    "            edges_weight[tuple(sorted(edge))] += 1\n",
    "        \n",
    "    else:\n",
    "        idx_object = list_id_tweet.index(id_tweet)\n",
    "        object_to_mod = collection_totale[idx_object]\n",
    "        object_to_mod._updateNumberRetweet(tweet)\n",
    "        object_to_mod._updateListUserRetweet(tweet)\n",
    "        collection_totale[idx_object] = object_to_mod\n",
    "        \n",
    "Graph = GraphHashtag(edges_weight, collection_totale, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: ['astori',\n",
       "              'senegalese',\n",
       "              'idydiene',\n",
       "              'omicidio',\n",
       "              'senegalesi',\n",
       "              'fioriere',\n",
       "              'fiorentina'],\n",
       "             1: ['viabilitos'],\n",
       "             2: ['lega'],\n",
       "             3: ['empoli'],\n",
       "             4: ['maratonamentana', 'roma', 'torino'],\n",
       "             5: ['a1'],\n",
       "             6: ['dimaio',\n",
       "              'calenda',\n",
       "              'italia',\n",
       "              '5marzo',\n",
       "              'elezionepolitiche2018'],\n",
       "             7: ['m5s'],\n",
       "             8: ['fipili'],\n",
       "             9: ['meteo',\n",
       "              'toscana',\n",
       "              'elezioni2018',\n",
       "              'siena',\n",
       "              'firenze',\n",
       "              'elezioni',\n",
       "              'grosseto',\n",
       "              'arezzo',\n",
       "              'elezionipolitiche2018',\n",
       "              'lariachetira',\n",
       "              'lariachetirala7',\n",
       "              'livorno',\n",
       "              'politica',\n",
       "              'lazio',\n",
       "              'maremma',\n",
       "              'vini',\n",
       "              'italy',\n",
       "              'tuscany',\n",
       "              '',\n",
       "              'bio',\n",
       "              'pitigliano',\n",
       "              'orbetello',\n",
       "              'jmo18',\n",
       "              'jmo2018',\n",
       "              'neve',\n",
       "              'snow',\n",
       "              'capalbio',\n",
       "              'news',\n",
       "              'pendolaritos',\n",
       "              'treni',\n",
       "              'pisa',\n",
       "              'poterealpopolo',\n",
       "              '4marzo',\n",
       "              'ilbasketlivorneselive',\n",
       "              'seriecgold',\n",
       "              'seriecsilver',\n",
       "              'pisanews',\n",
       "              'massacarrara'],\n",
       "             10: ['6marzo'],\n",
       "             11: ['seriec',\n",
       "              'sottil',\n",
       "              'cecina',\n",
       "              'rosignano',\n",
       "              'livornodailylive',\n",
       "              'basketball',\n",
       "              'lavoro',\n",
       "              'casapound',\n",
       "              'livcun',\n",
       "              'cuneo'],\n",
       "             12: ['elezioni4marzo2018', 'salvini'],\n",
       "             13: ['nardella'],\n",
       "             14: ['basilicata',\n",
       "              'renzi',\n",
       "              'pd',\n",
       "              'campania',\n",
       "              'lucca',\n",
       "              'livornotimeslive']})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph.__dict__['clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic(Graph.__dict__['tweet_clusters'], 'renzi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_hashtag = Hashtag('maremma', collection_totale)\n",
    "hashtag = obj_hashtag.__dict__\n",
    "\n",
    "lista_tweet = hashtag['lista_tweet'][0]\n",
    "num_tweet = len(lista_tweet)\n",
    "top_retweet = get_top_retweet(lista_tweet)\n",
    "list_vector_pie = sentiment_percentage(lista_tweet)\n",
    "list_unici_utenti = unique_cumulative_users(lista_tweet)\n",
    "stream_neg = stream_tweet(lista_tweet, 'negative')\n",
    "stream_pos = stream_tweet(lista_tweet, 'positive')\n",
    "lista_diz_hash = co_occurrences(get_list_hashtags(lista_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 1, 'y': 3.7}, {'x': 2, 'y': 96.3}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_vector_pie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = Topic(Graph.__dict__['tweet_clusters'], 'renzi')\n",
    "\n",
    "lista_tweet = topic.__dict__['tweet_topic']\n",
    "num_tweet = len(lista_tweet)\n",
    "top_retweet = get_top_retweet(lista_tweet)\n",
    "list_vector_pie = sentiment_percentage(lista_tweet)\n",
    "list_unici_utenti = unique_cumulative_users(lista_tweet)\n",
    "stream_neg = stream_tweet(lista_tweet, 'negative')\n",
    "stream_pos = stream_tweet(lista_tweet, 'positive')\n",
    "lista_diz_hash = co_occurrences(get_list_hashtags(lista_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '#renzi', 'x': 1, 'y': 65},\n",
       " {'label': '#pd', 'x': 2, 'y': 60},\n",
       " {'label': '#elezionipolitiche2018', 'x': 3, 'y': 6},\n",
       " {'label': '#m5s', 'x': 4, 'y': 6},\n",
       " {'label': '#elezioni', 'x': 5, 'y': 6},\n",
       " {'label': '#firenze', 'x': 6, 'y': 6},\n",
       " {'label': '#maratonamentana', 'x': 7, 'y': 4},\n",
       " {'label': '#calenda', 'x': 8, 'y': 4},\n",
       " {'label': '#5stelle', 'x': 9, 'y': 4},\n",
       " {'label': '#grosseto', 'x': 10, 'y': 4}]"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrences(get_list_hashtags(topic.__dict__['tweet_topic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph = GraphHashtag(edges_weight, collection_totale, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Tweet at 0x117347ba8>,\n",
       " <__main__.Tweet at 0x116342c18>,\n",
       " <__main__.Tweet at 0x116342fd0>,\n",
       " <__main__.Tweet at 0x116342d30>,\n",
       " <__main__.Tweet at 0x11631e6a0>,\n",
       " <__main__.Tweet at 0x11631e518>,\n",
       " <__main__.Tweet at 0x11631e208>,\n",
       " <__main__.Tweet at 0x11631e390>,\n",
       " <__main__.Tweet at 0x11631ebe0>,\n",
       " <__main__.Tweet at 0x11631ee10>,\n",
       " <__main__.Tweet at 0x11631ea20>,\n",
       " <__main__.Tweet at 0x116341518>,\n",
       " <__main__.Tweet at 0x1163414a8>,\n",
       " <__main__.Tweet at 0x116341278>,\n",
       " <__main__.Tweet at 0x116341c50>,\n",
       " <__main__.Tweet at 0x116341438>,\n",
       " <__main__.Tweet at 0x116341be0>,\n",
       " <__main__.Tweet at 0x116340780>,\n",
       " <__main__.Tweet at 0x116340710>,\n",
       " <__main__.Tweet at 0x116340be0>,\n",
       " <__main__.Tweet at 0x116340208>,\n",
       " <__main__.Tweet at 0x121f68748>,\n",
       " <__main__.Tweet at 0x1163405f8>,\n",
       " <__main__.Tweet at 0x116317f98>,\n",
       " <__main__.Tweet at 0x116317828>,\n",
       " <__main__.Tweet at 0x116317c50>,\n",
       " <__main__.Tweet at 0x116317eb8>,\n",
       " <__main__.Tweet at 0x116317fd0>,\n",
       " <__main__.Tweet at 0x1166139e8>,\n",
       " <__main__.Tweet at 0x116613588>,\n",
       " <__main__.Tweet at 0x116613c18>,\n",
       " <__main__.Tweet at 0x116613f60>,\n",
       " <__main__.Tweet at 0x116613fd0>,\n",
       " <__main__.Tweet at 0x116613550>,\n",
       " <__main__.Tweet at 0x116613d68>,\n",
       " <__main__.Tweet at 0x1166335c0>,\n",
       " <__main__.Tweet at 0x116633860>,\n",
       " <__main__.Tweet at 0x116633a58>,\n",
       " <__main__.Tweet at 0x116633278>,\n",
       " <__main__.Tweet at 0x116628400>,\n",
       " <__main__.Tweet at 0x116628048>,\n",
       " <__main__.Tweet at 0x116628ac8>,\n",
       " <__main__.Tweet at 0x116628be0>,\n",
       " <__main__.Tweet at 0x11662c748>,\n",
       " <__main__.Tweet at 0x11662c358>,\n",
       " <__main__.Tweet at 0x11662c048>,\n",
       " <__main__.Tweet at 0x11662ca58>,\n",
       " <__main__.Tweet at 0x11662c080>,\n",
       " <__main__.Tweet at 0x11662cef0>,\n",
       " <__main__.Tweet at 0x11662cd68>,\n",
       " <__main__.Tweet at 0x11660e128>,\n",
       " <__main__.Tweet at 0x11660e160>,\n",
       " <__main__.Tweet at 0x11660e208>,\n",
       " <__main__.Tweet at 0x11660e940>,\n",
       " <__main__.Tweet at 0x11660e438>,\n",
       " <__main__.Tweet at 0x11660ecf8>,\n",
       " <__main__.Tweet at 0x11660ef98>,\n",
       " <__main__.Tweet at 0x11660ef28>,\n",
       " <__main__.Tweet at 0x11660efd0>,\n",
       " <__main__.Tweet at 0x11661c048>,\n",
       " <__main__.Tweet at 0x11661c198>,\n",
       " <__main__.Tweet at 0x11661cb38>,\n",
       " <__main__.Tweet at 0x11661cb70>,\n",
       " <__main__.Tweet at 0x11661ceb8>,\n",
       " <__main__.Tweet at 0x11661c320>,\n",
       " <__main__.Tweet at 0x11661c630>,\n",
       " <__main__.Tweet at 0x1166380b8>,\n",
       " <__main__.Tweet at 0x116638470>,\n",
       " <__main__.Tweet at 0x1166383c8>,\n",
       " <__main__.Tweet at 0x116638400>,\n",
       " <__main__.Tweet at 0x116638978>,\n",
       " <__main__.Tweet at 0x116638908>,\n",
       " <__main__.Tweet at 0x116638ef0>,\n",
       " <__main__.Tweet at 0x116638358>,\n",
       " <__main__.Tweet at 0x116638860>,\n",
       " <__main__.Tweet at 0x116638f28>,\n",
       " <__main__.Tweet at 0x1166444a8>,\n",
       " <__main__.Tweet at 0x11633fef0>,\n",
       " <__main__.Tweet at 0x116ef6710>,\n",
       " <__main__.Tweet at 0x11633fcf8>,\n",
       " <__main__.Tweet at 0x11731da58>,\n",
       " <__main__.Tweet at 0x11731d6a0>,\n",
       " <__main__.Tweet at 0x11731dd30>,\n",
       " <__main__.Tweet at 0x11731dcc0>,\n",
       " <__main__.Tweet at 0x121c26828>,\n",
       " <__main__.Tweet at 0x121c3e3c8>,\n",
       " <__main__.Tweet at 0x121c3eef0>,\n",
       " <__main__.Tweet at 0x121c46c50>,\n",
       " <__main__.Tweet at 0x121c5df60>,\n",
       " <__main__.Tweet at 0x121c73a20>,\n",
       " <__main__.Tweet at 0x11643aa58>,\n",
       " <__main__.Tweet at 0x121c82550>,\n",
       " <__main__.Tweet at 0x121c9bdd8>,\n",
       " <__main__.Tweet at 0x121ca6860>,\n",
       " <__main__.Tweet at 0x121ccee10>,\n",
       " <__main__.Tweet at 0x121d10cc0>,\n",
       " <__main__.Tweet at 0x121d106d8>,\n",
       " <__main__.Tweet at 0x121d1fd30>,\n",
       " <__main__.Tweet at 0x121d1ff28>,\n",
       " <__main__.Tweet at 0x121d1f668>,\n",
       " <__main__.Tweet at 0x121d81828>,\n",
       " <__main__.Tweet at 0x121df81d0>,\n",
       " <__main__.Tweet at 0x121e3b7b8>,\n",
       " <__main__.Tweet at 0x116d8ab38>]"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph.__dict__['tweet_clusters']['renzi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = Graph.__dict__['clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_weights = edges(dict_list_hashtag, occurrences=False, jaccard=True)\n",
    "G = graph_hashtags(tuples_weights)\n",
    "\n",
    "# Assign id\n",
    "id_hash = {i: j for i, j in enumerate(list_hashtags)}\n",
    "hash_id = {j: i for i, j in id_hash.items()}\n",
    "\n",
    "dimensionality_reduct, num_components = dimensionality_reduction(G)\n",
    "clusters = clustering(dimensionality_reduct)\n",
    "class_hash, class_num_hash = create_cluster(G, clusters)\n",
    "\n",
    "set_tweets_class, set_hash_class = tweet_in_class(class_hash, class_num_hash, dict_hashtag, hashtags_dict)\n",
    "class_of_tweets, dict_tweet_prop_class, tweet_belongs_to = assign_tweet(list_tweet, hashtags_dict, class_num_hash,\n",
    "                                                                        class_hash)\n",
    "\n",
    "### Per prendere gli id dei tweet del topic devo matchare nome e numero topic\n",
    "output = []\n",
    "for cluster, list_hash in class_hash.items():\n",
    "    dictionary = {}\n",
    "    dictionary['topic'] = int(cluster)\n",
    "    dict_ha = {i: count_hashtags[i] for i in list_hash}\n",
    "    dictionary['hashtags'] = [(i, count_hashtags[i]) for i in sorted(dict_ha, key=dict_ha.get, reverse=True)]\n",
    "    dictionary['number_tweets'] = len(set(class_of_tweets[cluster]))\n",
    "\n",
    "    output += [dictionary]\n",
    "\n",
    "dict_topic_hash = defaultdict(list)\n",
    "for i in output:\n",
    "    dict_topic_hash[i['topic']] += [j for j in i['hashtags']]\n",
    "\n",
    "name_topic = {i: j[0][0] for i, j in dict_topic_hash.items()}\n",
    "print (name_topic)\n",
    "topic_nome = {j:i for i,j in name_topic.items()}\n",
    "\n",
    "with open('web-ui/src/data/name_topic.js', 'w') as outfile:\n",
    "    outfile.write('export default [')\n",
    "    max_name = len(name_topic)\n",
    "    for idx, t in enumerate(list(topic_nome.keys())):\n",
    "        if idx != max_name - 1:\n",
    "            outfile.write(\"'\"+t+\"'\"+',\\n')\n",
    "        else:\n",
    "            outfile.write(\"'\"+t+\"'\" + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
