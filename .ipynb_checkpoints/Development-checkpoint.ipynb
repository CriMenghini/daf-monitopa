{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "\n",
    "import preprocessor as p\n",
    "from kneed import  KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from src.preprocessing import normalize,\\\n",
    "                              substitute_label_,\\\n",
    "                              replace_word_index_twitter_\n",
    "\n",
    "\n",
    "# Lexicon polarity\n",
    "data = json.load(open('outputfile.json'))\n",
    "vocabolario_lexicon = json.load(open('data/lexicon_polarity.json'))\n",
    "vocabolario_index_twitter = json.load(open('data/vocabolario_twitter.json'))\n",
    "\n",
    "\n",
    "# Load Sentiment Analysis model\n",
    "with open('src/model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"src/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Da aggiungere quando c'è il database: check, tramite id, se il tweet è già nel db e aggiornare il \n",
    "count dei retweet\"\"\"\n",
    "\n",
    "class Tweet(object):\n",
    "    \"\"\"The class defines a tweet.\n",
    "\n",
    "    Attributes:\n",
    "    tweet_object: twitter streaming API object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 tweet_object,\n",
    "                 vocabolario_lexicon, \n",
    "                 vocabolario_index_twitter):\n",
    "\n",
    "        #self.tweet_object = tweet_object\n",
    "        self.is_a_retweet = self.is_a_retweet(tweet_object)\n",
    "        self.tweet_text = self.get_text(tweet_object)\n",
    "        self.id_tweet = self.get_id_tweet(tweet_object)\n",
    "        self.id_retweet = self.get_id_retweet(tweet_object)\n",
    "        self.num_retweet = self.get_number_retweets(tweet_object)\n",
    "        self.list_hashtags = self.get_hashtag()\n",
    "        self.data_tweet = self.get_date_tweet(tweet_object)\n",
    "        self.data_retweet = self.get_date_retweet(tweet_object)\n",
    "        self.user_tweet_id = self.get_user_tweet(tweet_object)\n",
    "        #self.user_retweet_id = self.get_user_retweet(tweet_object)\n",
    "        self.user_info = self.get_info_user_tweet(tweet_object)\n",
    "        self.normalized_text = self._textNormalization(vocabolario_lexicon,\n",
    "                                                        vocabolario_index_twitter) \n",
    "        self.padding = self._textPadding()\n",
    "        self.sentiment = self.sentiment()\n",
    "        self.changable_attributes = {'num_retweet': self.get_number_retweets(tweet_object),\n",
    "                                     'list_user_retweet': []}\n",
    "        \n",
    "          \n",
    "    def get_text(self, tweet_object):\n",
    "        \"\"\"Get text of tweet without preprocessing.\n",
    "\n",
    "        :return: tweet's text\n",
    "        \"\"\"      \n",
    "        if self.is_a_retweet:\n",
    "            return tweet_object['retweeted_status']['text']\n",
    "\n",
    "        return tweet_object['text']\n",
    "\n",
    "    def get_cleaned_text(self):\n",
    "        \"\"\"Get tweet's content.\n",
    "\n",
    "        :return: tweet's text\n",
    "        \"\"\"\n",
    "        text = self.tweet_text\n",
    "        clean_text = self.text_cleaning(text)\n",
    "        return clean_text\n",
    "        \n",
    "    @staticmethod\n",
    "    def text_cleaning(text_tweet):\n",
    "        \"\"\"Return text without url, emoji and mentions.\n",
    "\n",
    "        :param text_tweet:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION)\n",
    "        clean_text = p.clean(text_tweet)\n",
    "        return clean_text\n",
    "\n",
    "    def get_hashtag(self):\n",
    "        \"\"\"Return the list of hashtags in the tweet.\n",
    "\n",
    "        :return: list of hashtags in the tweet\n",
    "        \"\"\"\n",
    "\n",
    "        tweet_text = self.get_cleaned_text()\n",
    "        p.set_options(p.OPT.HASHTAG)\n",
    "        parsed_tweet = p.parse(tweet_text)\n",
    "        hashtags_ = parsed_tweet.hashtags\n",
    "        if hashtags_ is None:\n",
    "            return []\n",
    "\n",
    "        list_hashtags = [i.match[1:].lower() for i in hashtags_]\n",
    "        return list_hashtags\n",
    "\n",
    "    def is_a_retweet(self, tweet_object):\n",
    "        \"\"\"Tell if the post is a retweet or not.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            assert tweet_object['retweeted_status']\n",
    "            return True\n",
    "        except KeyError:\n",
    "            return False\n",
    "\n",
    "    def get_id_tweet(self, tweet_object):\n",
    "        \"\"\"Return the id of the first tweet\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.is_a_retweet:\n",
    "            return tweet_object['retweeted_status']['id']\n",
    "\n",
    "        return tweet_object['id']\n",
    "\n",
    "    def get_id_retweet(self, tweet_object):\n",
    "        \"\"\"Return the post id.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return tweet_object['id']\n",
    "\n",
    "    def get_number_retweets(self, tweet_object):\n",
    "        \"\"\"Number of retweet.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #if self.is_a_retweet:\n",
    "        #    return tweet_object['retweeted_status']['retweet_count']\n",
    "        \n",
    "        return tweet_object['retweet_count']\n",
    "        \n",
    "    \n",
    "    def get_date_tweet(self, tweet_object):\n",
    "        \"\"\"Publication date of the tweet\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.is_a_retweet:\n",
    "            return tweet_object['retweeted_status']['created_at']\n",
    "        \n",
    "        return tweet_object['created_at']\n",
    "\n",
    "    def get_date_retweet(self, tweet_object):\n",
    "        \"\"\"Pub date of retweet\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        return tweet_object['created_at']\n",
    "    \n",
    "    def get_user_tweet(self, tweet_object):\n",
    "        \"\"\"Return the user id that tweets\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.is_a_retweet:\n",
    "            return tweet_object['retweeted_status']['user']['id']\n",
    "        return tweet_object['user']['id']\n",
    "    \n",
    "    def get_info_user_tweet(self, tweet_object):\n",
    "        \"\"\"Return info of the user that tweets\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        info = {}\n",
    "        if self.is_a_retweet:\n",
    "            user = tweet_object['retweeted_status']['user']\n",
    "            info['name'] = user['name']\n",
    "            info['followers_count'] = user['followers_count']\n",
    "            return info\n",
    "        \n",
    "        user = tweet_object['user']\n",
    "        info['name'] = user['name']\n",
    "        info['followers_count'] = user['followers_count']\n",
    "        return info\n",
    "        \n",
    "    def get_user_retweet(self, tweet_object):\n",
    "        \"\"\"Return the user id that retweets\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        return tweet_object['user']['id']\n",
    "    \n",
    "            \n",
    "    def sentiment(self):\n",
    "        \"\"\"Tell if the tweet is positive or negative\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "  \n",
    "        if self._predictSentiment() == 0:\n",
    "            return 'negative'\n",
    "        \n",
    "        return 'positive'\n",
    "\n",
    "    \n",
    "    def _textPadding(self):\n",
    "        \"\"\"Return the sequence of padded words\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        max_length = 40\n",
    "        pad_text = np.append(np.array(self.normalized_text),\n",
    "                             np.array([0]*(max_length-len(self.normalized_text))))\n",
    "        \n",
    "        return pad_text\n",
    "            \n",
    "    def _textNormalization(self, vocabolario_lexicon, vocabolario_index_twitter):\n",
    "        \"\"\"Return the normalized text for padding.\n",
    "        \n",
    "        Keyword Arguments:\n",
    "        \"\"\"\n",
    "        \n",
    "        token_tweet = p.tokenize(self.tweet_text)\n",
    "        split_normalize_tweet = normalize(token_tweet).split()\n",
    "        replace_and_split_lexicon = (substitute_label_(split_normalize_tweet,\\\n",
    "                                                      vocabolario_lexicon)).split()\n",
    "        to_pad = replace_word_index_twitter_(replace_and_split_lexicon,\\\n",
    "                                            vocabolario_index_twitter)\n",
    "        \n",
    "        return to_pad\n",
    "\n",
    "    def _predictSentiment(self):\n",
    "        \"\"\"Return the sentimenti prediction for the Tweet\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        return loaded_model.predict_classes(np.array([self._textPadding(),]))\n",
    "    \n",
    "    def _updateNumberRetweet(self, tweet_object):\n",
    "        \"\"\"Update attributes\n",
    "        \n",
    "        :return:\"\"\"\n",
    "        \n",
    "        self.changable_attributes['num_retweet'] = max(self.num_retweet,\\\n",
    "                                                       self.get_number_retweets(tweet_object))\n",
    "        \n",
    "    def _updateListUserRetweet(self, tweet_object):\n",
    "        \"\"\"Update lista degli utenti che hanno retwittato\"\"\"\n",
    "        \n",
    "        self.changable_attributes['list_user_retweet'] += [(self.get_user_retweet(tweet_object),\\\n",
    "                                                            self.get_date_retweet(tweet_object))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetCollection(object):\n",
    "    \"\"\"The class define the collection of tweets related to\n",
    "    one hashtag.\n",
    "    \n",
    "    Attributes:\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hashtag, collection_totale):\n",
    "        \n",
    "        self.hashtag = hashtag\n",
    "        self.collection = self.collezione(collection_totale)\n",
    "        \n",
    "    def collezione(self, collection_totale):\n",
    "        \"\"\"Return the list of objects in the collection\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        collection = []\n",
    "        for tweet in collection_totale:\n",
    "            for hash_ in tweet.__dict__['list_hashtags']:\n",
    "                if self.hashtag in hash_ and tweet not in collection:\n",
    "                    collection += [tweet]\n",
    "                    \n",
    "        return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hashtag(object):\n",
    "    \"\"\"The class defines a hashtag object.\n",
    "\n",
    "    Attribute:\n",
    "    hashtag_occurrences_collection: occurence\n",
    "                                    of the hashtag in the collection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 hashtag,\n",
    "                 tweet_collection):\n",
    "        \"\"\"Return a hashtag object.\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.hashtag = hashtag\n",
    "        self.lista_tweet = self.get_list_tweet(tweet_collection)\n",
    "        self.lista_user = self.get_list_users()\n",
    "\n",
    "    def get_list_tweet(self, tweet_collection):\n",
    "        \"\"\"Return the list of tweets that contain the hashtag\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        collection = TweetCollection(self.hashtag,\\\n",
    "                                     tweet_collection).__dict__['collection']\n",
    "        lista_tweet = []\n",
    "        \n",
    "        # Considero solo i singoli tweet\n",
    "        for tweet in collection: \n",
    "            attr_tweet = tweet.__dict__\n",
    "            lista_id_tweet = [attr_tweet['id_tweet']]\n",
    "            lista_tweet += lista_id_tweet\n",
    "            \n",
    "        return collection, lista_tweet\n",
    "    \n",
    "    def get_list_users(self):\n",
    "        \"\"\"Return the list of users that tweet or\n",
    "        retweet the hashtag\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        list_users = []\n",
    "        for tweet in self.lista_tweet[0]:\n",
    "            tweet_attr = tweet.__dict__\n",
    "            id_user_tweet = [tweet_attr['user_tweet_id']]\n",
    "            id_user_retweet = tweet_attr['changable_attributes']['list_user_retweet']\n",
    "            \n",
    "            list_users += id_user_tweet + id_user_retweet\n",
    "            \n",
    "        return list_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Simulazione dell'arrivo dei tweet\"\"\"\n",
    "list_id_tweet = []\n",
    "list_hashtags = []\n",
    "collection_totale = []\n",
    "edges_weight = defaultdict(int)\n",
    "\n",
    "for tweet in data:\n",
    "    \n",
    "    object_tweet = Tweet(tweet, vocabolario_lexicon, vocabolario_index_twitter)\n",
    "    tweet_attr = object_tweet.__dict__\n",
    "    id_tweet = tweet_attr['id_tweet']\n",
    "    list_hashtag = tweet_attr['list_hashtags']\n",
    "    \n",
    "    if id_tweet not in list_id_tweet:\n",
    "        list_id_tweet += [id_tweet]\n",
    "        collection_totale += [object_tweet]\n",
    "        list_hashtags += list_hashtag\n",
    "        choose_two_hashtag = list(itertools.combinations(list_hashtag, 2))\n",
    "        for edge in choose_two_hashtag:\n",
    "            edges_weight[tuple(sorted(edge))] += 1\n",
    "        \n",
    "    else:\n",
    "        idx_object = list_id_tweet.index(id_tweet)\n",
    "        object_to_mod = collection_totale[idx_object]\n",
    "        object_to_mod._updateNumberRetweet(tweet)\n",
    "        object_to_mod._updateListUserRetweet(tweet)\n",
    "        collection_totale[idx_object] = object_to_mod\n",
    "        \n",
    "Graph = GraphHashtag(edges_weight, collection_totale, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_hashtag = Hashtag('maremma', collection_totale)\n",
    "hashtag = obj_hashtag.__dict__\n",
    "\n",
    "lista_tweet = hashtag['lista_tweet'][0]\n",
    "num_tweet = len(lista_tweet)\n",
    "top_retweet = get_top_retweet(lista_tweet)\n",
    "list_vector_pie = sentiment_percentage(lista_tweet)\n",
    "list_unici_utenti = unique_cumulative_users(lista_tweet)\n",
    "stream_neg = stream_tweet(lista_tweet, 'negative')\n",
    "stream_pos = stream_tweet(lista_tweet, 'positive')\n",
    "lista_diz_hash = co_occurrences(get_list_hashtags(lista_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphHashtag(object):\n",
    "    \"\"\"This class define the graph of hashtags.\n",
    "    \n",
    "    Attributes:\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, edge_weights, tweet_collection, with_jaccard):\n",
    "        self.with_jaccard = with_jaccard\n",
    "        self.G = self.create_graph(edge_weights, tweet_collection)\n",
    "        self.clusters = self.topic_content()\n",
    "        self.tweet_clusters = self.tweet_cluster(tweet_collection)\n",
    "        \n",
    "    \n",
    "    def create_graph(self, edge_weights, tweet_collection):\n",
    "        \"\"\"Return the graph of hashtags.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        G.add_weighted_edges_from(self._defineEdges(edge_weights, tweet_collection, self.with_jaccard))\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def topic_content(self):\n",
    "        \"\"\"Return the list of hashtag in the topic\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        partitions = self._graphPartitioning()\n",
    "        \n",
    "        hashtag_cluster = list(zip(self.G.nodes(),partitions.labels_))\n",
    "\n",
    "        cluster_list_hashtag = defaultdict(list)\n",
    "        for hash_, class_ in hashtag_cluster:\n",
    "            cluster_list_hashtag[class_] += [hash_]\n",
    "            \n",
    "        return cluster_list_hashtag\n",
    "    \n",
    "    def tweet_cluster(self, tweet_collection):\n",
    "        \"\"\"Return the list of tweets per topic\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        cluster_name = self._renameClusters(tweet_collection)\n",
    "        hash_cluster = {hash_:cluster \\\n",
    "                for cluster,list_hash in self.clusters.items()\\\n",
    "                for hash_ in list_hash}\n",
    "        \n",
    "        tweet_cluster = {}\n",
    "\n",
    "        for tweet in tweet_collection:\n",
    "            tweet_attr = tweet.__dict__\n",
    "            tweet_id = tweet_attr['id_tweet']\n",
    "            list_clusters = [hash_cluster[h] for h in tweet_attr['list_hashtags'] if h in self.G.nodes()]\n",
    "            tweet_cluster[tweet] = list(set(list_clusters))\n",
    "        \n",
    "        \"\"\"Sono esclusi i tweet che non appartengono a nessun cluster\"\"\"\n",
    "        cluster_tweet = defaultdict(list)\n",
    "        for tweet, list_cluster in tweet_cluster.items():\n",
    "            if len(list_cluster) > 0:\n",
    "                for cluster in list_cluster:\n",
    "                    cluster_tweet[cluster_name[cluster]] += [tweet]\n",
    "                    \n",
    "        return cluster_tweet\n",
    "        \n",
    "    \n",
    "    def _adjacencyMatrixReduction(self):\n",
    "        \"\"\"Return the matrix projected in the lower dimensional \n",
    "        principal components subspace.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        adjacency_matrix = nx.to_numpy_matrix(self.G)\n",
    "        X = adjacency_matrix\n",
    "        pca = PCA()\n",
    "        pca.fit(X)\n",
    "        variance = pca.explained_variance_ratio_\n",
    "        num_components = np.argmax(np.cumsum(variance)>.9)\n",
    "        #print (num_components)\n",
    "\n",
    "        X = adjacency_matrix\n",
    "        pca = PCA(n_components=num_components,svd_solver = 'arpack' )\n",
    "        pca.fit(X) \n",
    "        dimensionality_reduction = pca.fit_transform(X)\n",
    "        \n",
    "        return dimensionality_reduction\n",
    "    \n",
    "    def _graphPartitioning(self, max_k=50):\n",
    "        \"\"\"Give back the partitions.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        X = self._adjacencyMatrixReduction()\n",
    "        distortions = []\n",
    "        K = range(1,max_k)\n",
    "        for k in K:\n",
    "            kmeanModel = KMeans(n_clusters=k).fit(X)\n",
    "            distortions += [sum(np.min(cdist(X, \n",
    "                                             kmeanModel.cluster_centers_, \n",
    "                                             'euclidean'), \n",
    "                                       axis=1))\\\n",
    "                            / X.shape[0]]\n",
    "\n",
    "        number_partitions = KneeLocator(list(K), \n",
    "                                        distortions, \n",
    "                                        invert=False, \n",
    "                                        direction='decreasing')\n",
    "        \n",
    "        return KMeans(n_clusters=number_partitions.knee).fit(X)\n",
    "    \n",
    "    def _defineEdges(self, edge_weights, tweet_collection, jaccard=True):\n",
    "        \"\"\"Return the list of weighted edges.\n",
    "        \n",
    "        :return:\n",
    "        \n",
    "        Keyword Arguments\n",
    "        :param:\n",
    "        \"\"\"\n",
    "        \n",
    "        edge_weights = {key:w for key, w in edge_weights.items() if w > 4}\n",
    "        \n",
    "        \n",
    "        list_obj_hashtag = {}\n",
    "        list_weighted_edges = []\n",
    "        for h_1, h_2 in edge_weights.keys(): # Questa parte va integrata \n",
    "                                             # nel processo di ingestion \n",
    "                                             # del singolo tweet al fine\n",
    "                                             # di snellire la computazione\n",
    "            if h_1 not in list_obj_hashtag:\n",
    "                hashtag_1 = len(Hashtag(h_1, tweet_collection)\\\n",
    "                                .__dict__['lista_tweet'][1])\n",
    "                list_obj_hashtag[h_1] = hashtag_1\n",
    "            else:\n",
    "                hashtag_1 = list_obj_hashtag[h_1]\n",
    "\n",
    "            if h_2 not in list_obj_hashtag:\n",
    "                hashtag_2 = len(Hashtag(h_2, tweet_collection)\\\n",
    "                                .__dict__['lista_tweet'][1])\n",
    "                list_obj_hashtag[h_2] = hashtag_2\n",
    "            else:\n",
    "                hashtag_2 = list_obj_hashtag[h_2]\n",
    "                    \n",
    "            if jaccard:\n",
    "                list_weighted_edges += [(h_1, \n",
    "                                     h_2, \n",
    "                                     edge_weights[(h_1, h_2)]\\\n",
    "                                     /(hashtag_1 + hashtag_2))]\n",
    "            else:\n",
    "               \n",
    "                \n",
    "                list_weighted_edges += [(h_1, \n",
    "                                         h_2, \n",
    "                                         edge_weights[(h_1, h_2)])]\n",
    "        \n",
    "        return list_weighted_edges       \n",
    "    \n",
    "    def _defineNodes(self, edge_weights, tweet_collection):\n",
    "        \"\"\"Get the list of nodes\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        list_nodes = []\n",
    "        edges = self._defineEdges(edge_weights, tweet_collection, jaccard=self.with_jaccard)\n",
    "        for h_1, h_2, w in edges:\n",
    "            list_nodes += [h_1, h_2]\n",
    "            \n",
    "        return set(list_nodes)\n",
    "    \n",
    "    def _renameClusters(self, tweet_collection):\n",
    "        \"\"\"Map the cluster to a name corresponding to the \n",
    "        most occurrent word.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        name_cluster = {}\n",
    "        for cluster, list_hash in self.clusters.items():\n",
    "            list_occ = []\n",
    "            for h in list_hash:\n",
    "                list_occ += [len(Hashtag(h, tweet_collection).__dict__['lista_tweet'])]\n",
    "\n",
    "            name_cluster[cluster] = list_hash[np.argmax(list_occ)]\n",
    "            \n",
    "        return name_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Topic(object):\n",
    "    \"\"\"The class defines the info of a topic.\n",
    "    \n",
    "    Attributes:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tweet_clusters, topic):\n",
    "        self.topic = topic\n",
    "        self.tweet_topic = self.tweet_topic(tweet_clusters)\n",
    "        \n",
    "    def tweet_topic(self, tweet_clusters):\n",
    "        \"\"\"Get tweets in the topic.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        return tweet_clusters[self.topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = Topic(Graph.__dict__['tweet_clusters'], 'renzi')\n",
    "\n",
    "lista_tweet = topic.__dict__['tweet_topic']\n",
    "num_tweet = len(lista_tweet)\n",
    "top_retweet = get_top_retweet(lista_tweet)\n",
    "list_vector_pie = sentiment_percentage(lista_tweet)\n",
    "list_unici_utenti = unique_cumulative_users(lista_tweet)\n",
    "stream_neg = stream_tweet(lista_tweet, 'negative')\n",
    "stream_pos = stream_tweet(lista_tweet, 'positive')\n",
    "lista_diz_hash = co_occurrences(get_list_hashtags(lista_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_retweet(lista_tweet):\n",
    "        \"\"\"Return the list of top retweets\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        list_num_retweet = []\n",
    "        for tweet in lista_tweet:\n",
    "            tweet_attr = tweet.__dict__\n",
    "            num_retweet = tweet_attr['num_retweet']\n",
    "            text_tweet = tweet.text_cleaning(tweet_attr['tweet_text'])\n",
    "            user_info = tweet_attr['user_info']\n",
    "            list_num_retweet += [(num_retweet,\\\n",
    "                                  text_tweet,\\\n",
    "                                  user_info)]\n",
    "            \n",
    "        sort_retweet = sorted(list_num_retweet,key=itemgetter(0), reverse=True)[:10]\n",
    "        \n",
    "        top_10_retweet = []\n",
    "        for i, t in enumerate(sort_retweet):\n",
    "            x = i+1\n",
    "            y = t[0]\n",
    "            label = t[1] + '\\n' + 'Autore: ' + t[2]['name'] + '\\n' \\\n",
    "                    + 'Followers: ' + str(t[2]['followers_count'])\n",
    "                                           \n",
    "            top_10_retweet += [{'x':x, 'y':y, 'label':label}]\n",
    "            \n",
    "        return top_10_retweet\n",
    "    \n",
    "\n",
    "def sentiment_percentage(lista_tweet):\n",
    "        \"\"\"Return the percentage of positive and \n",
    "        negative tweets.\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        sentiment_tweet = []\n",
    "        for tweet in lista_tweet:\n",
    "            tweet_attr = tweet.__dict__\n",
    "            sentiment_tweet += [tweet_attr['sentiment']]\n",
    "            \n",
    "        count_sentiment = collections.Counter(sentiment_tweet)\n",
    "        total = len(sentiment_tweet)\n",
    "        percentuali_sentiment = [{'x':1, 'y':round(count_sentiment['positive']/total*100,1)},\n",
    "                                 {'x':2, 'y':round(count_sentiment['negative']/total*100,1)}]\n",
    "            \n",
    "        return percentuali_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate_date(lista_date):\n",
    "    \"\"\"Return the manipulate dates.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    ts = pd.to_datetime(lista_date)\n",
    "    ts_list = []\n",
    "    for time in ts:\n",
    "        t = str(time)\n",
    "        t_day = t[:10]\n",
    "        t_hour = t[10:13] + ':00:00'\n",
    "        t_rest = t[19:]\n",
    "\n",
    "        ts_list += [t_day + t_hour + t_rest]\n",
    "\n",
    "    return ts_list\n",
    "\n",
    "def unique_cumulative_users(lista_tweet):\n",
    "    \"\"\"Return the cumulative sum of unique users.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    list_date_id = []\n",
    "    for tweet in lista_tweet:\n",
    "        tweet_attr = tweet.__dict__\n",
    "        list_date_id += tweet_attr['changable_attributes']['list_user_retweet']\n",
    "\n",
    "\n",
    "    lista_date = [j for i, j in list_date_id]\n",
    "    ts_list = manipulate_date(lista_date)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['Time'] = ts_list\n",
    "    df['user'] = [i for i, j in list_date_id]\n",
    "    df['counter'] = [1] * len(list_date_id)\n",
    "\n",
    "    df.sort_values(by='Time', inplace=True)\n",
    "    unique_count = df.drop_duplicates('user', keep='first')\\\n",
    "                     .groupby('Time')['counter']\\\n",
    "                     .sum()\n",
    "    cumulative_unique_user = unique_count.cumsum()\n",
    "\n",
    "    list_unici_utenti = []\n",
    "    for i in cumulative_unique_user.index:\n",
    "        list_unici_utenti += [{'x': str(i),\n",
    "                               'y': int(cumulative_unique_user.loc[i])}]\n",
    "\n",
    "    return list_unici_utenti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_tweet(lista_tweet, sentimento='negative'):\n",
    "    \"\"\"Return the stram of positive/negative tweets\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    list_date = []\n",
    "    for tweet in lista_tweet:\n",
    "        tweet_attr = tweet.__dict__\n",
    "        if tweet_attr['sentiment'] == sentimento:\n",
    "            list_date += [tweet_attr['data_retweet']]\n",
    "\n",
    "    ts_list = manipulate_date(list_date)\n",
    "\n",
    "    ts = pd.to_datetime(ts_list)\n",
    "    df = pd.DataFrame()\n",
    "    df['Time'] = ts\n",
    "    df['freq'] = [1] * len(ts)\n",
    "\n",
    "    grouped = df.groupby('Time').sum()\n",
    "    list_hours = []\n",
    "    for i in grouped.index:\n",
    "        list_hours += [{'a': str(i), 'b': int(grouped.loc[i][0])}]\n",
    "\n",
    "    return list_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_hashtags(lista_tweet):\n",
    "    \"\"\"Return the list of co-occurrent hashtags.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    list_hashtags = []\n",
    "    for tweet in lista_tweet:\n",
    "        tweet_attr = tweet.__dict__\n",
    "        list_hashtags += tweet_attr['list_hashtags']\n",
    "\n",
    "    return collections.Counter(list_hashtags).most_common(11)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrences(lista_hashtag):\n",
    "    \"\"\"Return the top 10 co-occurrent hashtags\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    lista_co_occ = []\n",
    "    for i, hash_ in enumerate(lista_hashtag):\n",
    "        lista_co_occ += [{'x': i + 1, 'y': hash_[1], 'label': '#' + hash_[0]}]\n",
    "\n",
    "    return lista_co_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '#renzi', 'x': 1, 'y': 65},\n",
       " {'label': '#pd', 'x': 2, 'y': 60},\n",
       " {'label': '#elezionipolitiche2018', 'x': 3, 'y': 6},\n",
       " {'label': '#m5s', 'x': 4, 'y': 6},\n",
       " {'label': '#elezioni', 'x': 5, 'y': 6},\n",
       " {'label': '#firenze', 'x': 6, 'y': 6},\n",
       " {'label': '#maratonamentana', 'x': 7, 'y': 4},\n",
       " {'label': '#calenda', 'x': 8, 'y': 4},\n",
       " {'label': '#5stelle', 'x': 9, 'y': 4},\n",
       " {'label': '#grosseto', 'x': 10, 'y': 4}]"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrences(get_list_hashtags(topic.__dict__['tweet_topic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph = GraphHashtag(edges_weight, collection_totale, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Tweet at 0x117347ba8>,\n",
       " <__main__.Tweet at 0x116342c18>,\n",
       " <__main__.Tweet at 0x116342fd0>,\n",
       " <__main__.Tweet at 0x116342d30>,\n",
       " <__main__.Tweet at 0x11631e6a0>,\n",
       " <__main__.Tweet at 0x11631e518>,\n",
       " <__main__.Tweet at 0x11631e208>,\n",
       " <__main__.Tweet at 0x11631e390>,\n",
       " <__main__.Tweet at 0x11631ebe0>,\n",
       " <__main__.Tweet at 0x11631ee10>,\n",
       " <__main__.Tweet at 0x11631ea20>,\n",
       " <__main__.Tweet at 0x116341518>,\n",
       " <__main__.Tweet at 0x1163414a8>,\n",
       " <__main__.Tweet at 0x116341278>,\n",
       " <__main__.Tweet at 0x116341c50>,\n",
       " <__main__.Tweet at 0x116341438>,\n",
       " <__main__.Tweet at 0x116341be0>,\n",
       " <__main__.Tweet at 0x116340780>,\n",
       " <__main__.Tweet at 0x116340710>,\n",
       " <__main__.Tweet at 0x116340be0>,\n",
       " <__main__.Tweet at 0x116340208>,\n",
       " <__main__.Tweet at 0x121f68748>,\n",
       " <__main__.Tweet at 0x1163405f8>,\n",
       " <__main__.Tweet at 0x116317f98>,\n",
       " <__main__.Tweet at 0x116317828>,\n",
       " <__main__.Tweet at 0x116317c50>,\n",
       " <__main__.Tweet at 0x116317eb8>,\n",
       " <__main__.Tweet at 0x116317fd0>,\n",
       " <__main__.Tweet at 0x1166139e8>,\n",
       " <__main__.Tweet at 0x116613588>,\n",
       " <__main__.Tweet at 0x116613c18>,\n",
       " <__main__.Tweet at 0x116613f60>,\n",
       " <__main__.Tweet at 0x116613fd0>,\n",
       " <__main__.Tweet at 0x116613550>,\n",
       " <__main__.Tweet at 0x116613d68>,\n",
       " <__main__.Tweet at 0x1166335c0>,\n",
       " <__main__.Tweet at 0x116633860>,\n",
       " <__main__.Tweet at 0x116633a58>,\n",
       " <__main__.Tweet at 0x116633278>,\n",
       " <__main__.Tweet at 0x116628400>,\n",
       " <__main__.Tweet at 0x116628048>,\n",
       " <__main__.Tweet at 0x116628ac8>,\n",
       " <__main__.Tweet at 0x116628be0>,\n",
       " <__main__.Tweet at 0x11662c748>,\n",
       " <__main__.Tweet at 0x11662c358>,\n",
       " <__main__.Tweet at 0x11662c048>,\n",
       " <__main__.Tweet at 0x11662ca58>,\n",
       " <__main__.Tweet at 0x11662c080>,\n",
       " <__main__.Tweet at 0x11662cef0>,\n",
       " <__main__.Tweet at 0x11662cd68>,\n",
       " <__main__.Tweet at 0x11660e128>,\n",
       " <__main__.Tweet at 0x11660e160>,\n",
       " <__main__.Tweet at 0x11660e208>,\n",
       " <__main__.Tweet at 0x11660e940>,\n",
       " <__main__.Tweet at 0x11660e438>,\n",
       " <__main__.Tweet at 0x11660ecf8>,\n",
       " <__main__.Tweet at 0x11660ef98>,\n",
       " <__main__.Tweet at 0x11660ef28>,\n",
       " <__main__.Tweet at 0x11660efd0>,\n",
       " <__main__.Tweet at 0x11661c048>,\n",
       " <__main__.Tweet at 0x11661c198>,\n",
       " <__main__.Tweet at 0x11661cb38>,\n",
       " <__main__.Tweet at 0x11661cb70>,\n",
       " <__main__.Tweet at 0x11661ceb8>,\n",
       " <__main__.Tweet at 0x11661c320>,\n",
       " <__main__.Tweet at 0x11661c630>,\n",
       " <__main__.Tweet at 0x1166380b8>,\n",
       " <__main__.Tweet at 0x116638470>,\n",
       " <__main__.Tweet at 0x1166383c8>,\n",
       " <__main__.Tweet at 0x116638400>,\n",
       " <__main__.Tweet at 0x116638978>,\n",
       " <__main__.Tweet at 0x116638908>,\n",
       " <__main__.Tweet at 0x116638ef0>,\n",
       " <__main__.Tweet at 0x116638358>,\n",
       " <__main__.Tweet at 0x116638860>,\n",
       " <__main__.Tweet at 0x116638f28>,\n",
       " <__main__.Tweet at 0x1166444a8>,\n",
       " <__main__.Tweet at 0x11633fef0>,\n",
       " <__main__.Tweet at 0x116ef6710>,\n",
       " <__main__.Tweet at 0x11633fcf8>,\n",
       " <__main__.Tweet at 0x11731da58>,\n",
       " <__main__.Tweet at 0x11731d6a0>,\n",
       " <__main__.Tweet at 0x11731dd30>,\n",
       " <__main__.Tweet at 0x11731dcc0>,\n",
       " <__main__.Tweet at 0x121c26828>,\n",
       " <__main__.Tweet at 0x121c3e3c8>,\n",
       " <__main__.Tweet at 0x121c3eef0>,\n",
       " <__main__.Tweet at 0x121c46c50>,\n",
       " <__main__.Tweet at 0x121c5df60>,\n",
       " <__main__.Tweet at 0x121c73a20>,\n",
       " <__main__.Tweet at 0x11643aa58>,\n",
       " <__main__.Tweet at 0x121c82550>,\n",
       " <__main__.Tweet at 0x121c9bdd8>,\n",
       " <__main__.Tweet at 0x121ca6860>,\n",
       " <__main__.Tweet at 0x121ccee10>,\n",
       " <__main__.Tweet at 0x121d10cc0>,\n",
       " <__main__.Tweet at 0x121d106d8>,\n",
       " <__main__.Tweet at 0x121d1fd30>,\n",
       " <__main__.Tweet at 0x121d1ff28>,\n",
       " <__main__.Tweet at 0x121d1f668>,\n",
       " <__main__.Tweet at 0x121d81828>,\n",
       " <__main__.Tweet at 0x121df81d0>,\n",
       " <__main__.Tweet at 0x121e3b7b8>,\n",
       " <__main__.Tweet at 0x116d8ab38>]"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph.__dict__['tweet_clusters']['renzi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = Graph.__dict__['clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_weights = edges(dict_list_hashtag, occurrences=False, jaccard=True)\n",
    "G = graph_hashtags(tuples_weights)\n",
    "\n",
    "# Assign id\n",
    "id_hash = {i: j for i, j in enumerate(list_hashtags)}\n",
    "hash_id = {j: i for i, j in id_hash.items()}\n",
    "\n",
    "dimensionality_reduct, num_components = dimensionality_reduction(G)\n",
    "clusters = clustering(dimensionality_reduct)\n",
    "class_hash, class_num_hash = create_cluster(G, clusters)\n",
    "\n",
    "set_tweets_class, set_hash_class = tweet_in_class(class_hash, class_num_hash, dict_hashtag, hashtags_dict)\n",
    "class_of_tweets, dict_tweet_prop_class, tweet_belongs_to = assign_tweet(list_tweet, hashtags_dict, class_num_hash,\n",
    "                                                                        class_hash)\n",
    "\n",
    "### Per prendere gli id dei tweet del topic devo matchare nome e numero topic\n",
    "output = []\n",
    "for cluster, list_hash in class_hash.items():\n",
    "    dictionary = {}\n",
    "    dictionary['topic'] = int(cluster)\n",
    "    dict_ha = {i: count_hashtags[i] for i in list_hash}\n",
    "    dictionary['hashtags'] = [(i, count_hashtags[i]) for i in sorted(dict_ha, key=dict_ha.get, reverse=True)]\n",
    "    dictionary['number_tweets'] = len(set(class_of_tweets[cluster]))\n",
    "\n",
    "    output += [dictionary]\n",
    "\n",
    "dict_topic_hash = defaultdict(list)\n",
    "for i in output:\n",
    "    dict_topic_hash[i['topic']] += [j for j in i['hashtags']]\n",
    "\n",
    "name_topic = {i: j[0][0] for i, j in dict_topic_hash.items()}\n",
    "print (name_topic)\n",
    "topic_nome = {j:i for i,j in name_topic.items()}\n",
    "\n",
    "with open('web-ui/src/data/name_topic.js', 'w') as outfile:\n",
    "    outfile.write('export default [')\n",
    "    max_name = len(name_topic)\n",
    "    for idx, t in enumerate(list(topic_nome.keys())):\n",
    "        if idx != max_name - 1:\n",
    "            outfile.write(\"'\"+t+\"'\"+',\\n')\n",
    "        else:\n",
    "            outfile.write(\"'\"+t+\"'\" + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
